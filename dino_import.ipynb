{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import Dinov2Config, Dinov2ForImageClassification, AutoImageProcessor\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the smallest DINOv2 model\n",
    "model_name = \"facebook/dinov2-small\"\n",
    "config = Dinov2Config.from_pretrained(model_name)\n",
    "model = Dinov2ForImageClassification.from_pretrained(model_name)\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Modify the classifier for your number of classes\n",
    "num_classes = 10  # Change this to match your dataset\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std),\n",
    "])\n",
    "\n",
    "# Load your custom dataset\n",
    "data_dir = \"/path/to/your/dataset\"  # Change this to your dataset path\n",
    "dataset = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# Split dataset into train and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)  # Using a lower learning rate as suggested\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "    print(f\"Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "    print(f\"Val Accuracy: {100*correct/total:.2f}%\")\n",
    "    print()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save(model.state_dict(), \"fine_tuned_dinov2_small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchgeo.datasets import BigEarthNet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set the root directory where you want to store the dataset\n",
    "root = \"path/to/your/data/directory\"\n",
    "\n",
    "# Define transforms (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the BigEarthNet dataset\n",
    "# Set download=True to download the dataset if it's not already present\n",
    "dataset = BigEarthNet(\n",
    "    root=root,\n",
    "    split=\"train\",  # You can change this to \"val\" or \"test\" as needed\n",
    "    bands=\"rgb\",    # You can use \"all\" for all bands, or \"s1\" for Sentinel-1 bands\n",
    "    num_classes=19, # You can set this to 43 for the full set of classes\n",
    "    transforms=transform,\n",
    "    download=True,\n",
    "    checksum=True   # Verify the integrity of downloaded files\n",
    ")\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Example of iterating through the dataset\n",
    "for batch in dataloader:\n",
    "    images = batch['image']\n",
    "    labels = batch['label']\n",
    "    \n",
    "    # Your training or processing code here\n",
    "    print(f\"Batch image shape: {images.shape}\")\n",
    "    print(f\"Batch label shape: {labels.shape}\")\n",
    "    break  # Remove this to process all batches\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
